\documentclass[a4paper,11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{graphicx}
\usepackage{array}
\usepackage{booktabs}
\usepackage{float}
\usepackage{pifont}
\usepackage{xcolor}
\usepackage{threeparttable}

% Bewertungssymbole
\newcommand{\cmark}{\textcolor{green!70!black}{\ding{51}}}  % Erfüllt
\newcommand{\wmark}{\textcolor{orange}{\ding{115}}}        % Teilweise
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}            % Nicht erfüllt

\usepackage[scaled]{helvet}
\renewcommand{\familydefault}{\sfdefault}

\usepackage[a4paper, top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}

\usepackage{setspace}
\setstretch{1.5}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

\usepackage{microtype}
\sloppy

\usepackage{titlesec}
\titleformat{\section}{\normalfont\fontsize{12}{14}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\fontsize{12}{14}\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalfont\fontsize{11}{13}\bfseries}{\thesubsubsection}{1em}{}

\usepackage[colorlinks=true,linkcolor=black,citecolor=blue,urlcolor=blue]{hyperref}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[C]{\thepage}

\usepackage[german=quotes]{csquotes}

\usepackage{caption}
\captionsetup[table]{font=small,skip=10pt,labelfont=bf}

\usepackage[backend=biber, style=apa]{biblatex}
\addbibresource{references.bib}

\begin{document}

\begin{titlepage}
    \thispagestyle{empty}
    \centering
    \vspace*{5cm}
    {\Huge\bfseries Komponentenauswahl und Erläuterung zur Umsetzung \par}
    \vspace{1cm}
    {\Large KI-basierte Sprachübersetzer im Unternehmenskontext \par}
    \vspace{0.5cm}
    {\large Projekt: Generative KI im Unternehmenskontext (DLBFMPGKIU01) \par}
    \vspace{1cm}
    {\large Sven Behrens \par}
    {\large Matrikelnummer: 42303511 \par}
    \vspace{0.5cm}
    {\large Tutor: Prof. Dr. Oliver Dorn \par}
    \vspace{0.5cm}
    {\large \today \par}
\end{titlepage}

\pagenumbering{arabic}
\setcounter{page}{1}

\section{Einleitung}

Für die Umsetzung des Übersetzungs-Demonstrators ist die Auswahl einer geeigneten Übersetzungskomponente erforderlich. 
Diese Dokumentation beschreibt das systematische Auswahlverfahren basierend auf den definierten Anforderungen.

\section{Untersuchte Optionen}

Folgende Übersetzungslösungen wurden analysiert:

\begin{table}[H]
\centering
\caption{Übersicht der untersuchten Lösungen}
\begin{tabular}{p{4cm}p{3cm}p{6.5cm}}
\toprule
\textbf{Lösung} & \textbf{Typ} & \textbf{Kurzbeschreibung} \\
\midrule
DeepL API (Pro) & Cloud-API & Spezialisierte Übersetzungs-API, Fokus auf EU-Sprachen \parencite{deepl2024llm} \\
Google Cloud Translation & Cloud-API & Breites Sprachangebot (133 Sprachen) \parencite{languageio2025} \\
Microsoft Azure Translator & Cloud-API & Enterprise-Lösung mit Compliance-Fokus \parencite{microsoft2024notrace} \\
Amazon Translate & Cloud-API & AWS-integrierte Übersetzungslösung \parencite{aws2024translate} \\
OpenAI GPT-4 & LLM-API & Generatives Sprachmodell mit Übersetzungsfähigkeit \parencite{getblend2025llm} \\
Anthropic Claude & LLM-API & Generatives Sprachmodell, großer Kontext \parencite{getblend2025llm} \\
Meta NLLB-200 & Open-Source & Vielsprachiges Übersetzungsmodell \parencite{wmt2024findings} \\
Helsinki OPUS-MT & Open-Source & Sprachpaarspezifische Modelle \parencite{wmt2024findings} \\
\bottomrule
\end{tabular}
\end{table}

\section{Bewertung anhand der Anforderungen}

Die Lösungen werden anhand der in der Anforderungsliste definierten Kriterien bewertet.
Die Bewertung erfolgt mit: \cmark{} = erfüllt, \wmark{} = teilweise erfüllt, \xmark{} = nicht erfüllt.

\subsection{Funktionale Anforderungen}

\begin{table}[H]
\centering
\caption{Bewertung funktionaler Anforderungen}
\footnotesize
\begin{tabular}{p{2.5cm}cccccccc}
\toprule
\textbf{Anforderung} & \textbf{DeepL} & \textbf{Azure} & \textbf{Google} & \textbf{Amazon} & \textbf{GPT-4} & \textbf{Claude} & \textbf{NLLB} & \textbf{OPUS} \\
\midrule
REST-API verfügbar & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \wmark & \wmark \\
Sprachen DE/EN/FR/ES & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
Batch-Übersetzung & \cmark & \cmark & \cmark & \cmark & \wmark & \wmark & \wmark & \wmark \\
Spracherkennung & \cmark & \cmark & \cmark & \cmark & \wmark & \wmark & \wmark & \wmark \\
\bottomrule
\end{tabular}
\end{table}

DeepL, Azure, Google und Amazon bieten vollständige REST-APIs mit automatischer Spracherkennung und Batch-Verarbeitung \parencite{deepl2024api, microsoft2024notrace, aws2024translate}.
GPT-4 und Claude erfordern Prompt-basierte Integration; Claude bietet keine dedizierte Batch-API, ermöglicht aber parallele Requests \parencite{anthropic2024api}.
Die Open-Source-Modelle NLLB und OPUS-MT benötigen eigene API-Wrapper und externe Spracherkennungslösungen \parencite{picovoice2025opensource}.

\subsection{Nicht-funktionale Anforderungen}

\begin{table}[H]
\centering
\caption{Bewertung nicht-funktionaler Anforderungen}
\footnotesize
\begin{tabular}{p{2.5cm}cccccccc}
\toprule
\textbf{Anforderung} & \textbf{DeepL} & \textbf{Azure} & \textbf{Google} & \textbf{Amazon} & \textbf{GPT-4} & \textbf{Claude} & \textbf{NLLB} & \textbf{OPUS} \\
\midrule
Übersetzungsqualität & \cmark & \wmark & \cmark & \cmark & \cmark & \cmark & \wmark & \wmark \\
Antwortzeit < 3s & \cmark & \cmark & \cmark & \cmark & \wmark & \wmark & \wmark & \cmark \\
Kosten < 100€/Monat & \wmark & \cmark & \wmark & \cmark & \wmark & \wmark & \cmark & \cmark \\
100 parallele Anfragen & \wmark & \cmark & \cmark & \cmark & \xmark & \wmark & \wmark & \wmark \\
API-Key-Auth & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark \\
OpenAPI/Swagger-Doku & \cmark & \wmark & \wmark & \wmark & \wmark & \wmark & \xmark & \xmark \\
HTTPS-Verschlüsselung & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \wmark & \wmark \\
\bottomrule
\end{tabular}
\end{table}

DeepL und Claude liefern die höchste Übersetzungsqualität. Claude wurde in Tests als „Translation Champion" bezeichnet \parencite{taia2025comparison, getblend2025llm}.
Azure und Amazon bieten das beste Preis-Leistungs-Verhältnis mit ca. 10--15\$/Mio Zeichen und Free-Tier-Optionen \parencite{azure2024limits, aws2024translate}.
GPT-4 und Claude zeigen hohe Qualität, aber längere Antwortzeiten und bei Claude strikte Rate-Limits \parencite{openai2024terms, anthropic2024ratelimits}.
Open-Source-Lösungen erfordern Selbsthosting mit eigener TLS-Konfiguration.


\subsection{Rechtliche und ethische Anforderungen}

\begin{table}[H]
\centering
\caption{Bewertung rechtlicher und ethischer Anforderungen}
\footnotesize
\begin{tabular}{p{2.5cm}cccccccc}
\toprule
\textbf{Anforderung} & \textbf{DeepL} & \textbf{Azure} & \textbf{Google} & \textbf{Amazon} & \textbf{GPT-4} & \textbf{Claude} & \textbf{NLLB} & \textbf{OPUS} \\
\midrule
DSGVO-konform & \cmark & \cmark & \cmark & \wmark & \wmark & \cmark & \cmark & \cmark \\
Kein Modelltraining & \cmark & \cmark & \cmark & \wmark & \cmark & \cmark & \cmark & \cmark \\
Daten-Eigentum Nutzer & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
Kein Halluzinieren & \cmark & \cmark & \cmark & \cmark & \wmark & \wmark & \cmark & \cmark \\
Kommerzielle Nutzung & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark & \cmark \\
Transparente Datenverarb. & \cmark & \cmark & \cmark & \cmark & \wmark & \cmark & \cmark & \cmark \\
\bottomrule
\end{tabular}
\end{table}

DeepL, Azure, Google und Claude sind DSGVO-konform und nutzen keine Kundendaten zum Modelltraining \parencite{deepl2024privacy, microsoft2024notrace, google2024datausage, anthropic2024privacy}.
Amazon Translate speichert standardmäßig Daten zur Modellverbesserung. Ein Opt-Out ist erforderlich \parencite{aws2024translate}.
OpenAI speichert API-Daten 30 Tage zur Missbrauchsprüfung \parencite{techcrunch2023openai}.
Meta NLLB ist unter CC-BY-NC 4.0 lizenziert und daher nicht kommerziell nutzbar \parencite{picovoice2025opensource}.
OPUS-MT-Modelle sind unter CC-BY 4.0 frei verfügbar.

\section{Zusammenfassung und Empfehlung}

\begin{table}[H]
\centering
\caption{Gesamtbewertung der Lösungen}
\small
\begin{tabular}{p{4cm}ccp{6cm}}
\toprule
\textbf{Lösung} & \textbf{Eignung} & \textbf{Rang} & \textbf{Begründung} \\
\midrule
DeepL API (Pro) & \cmark & 1 & Höchste Qualität für DE/EN/FR/ES, DSGVO-konform \\
Microsoft Azure Translator & \cmark & 2 & Bestes Preis-Leistungs-Verhältnis, skalierbar \\
Amazon Translate & \cmark & 3 & Günstig, schnell, aber Opt-Out für DSGVO nötig \\
Google Cloud Translation & \wmark & 4 & Solide Qualität, aber teurer als Azure/Amazon \\
Anthropic Claude & \wmark & 5 & Sehr hohe Qualität, aber langsamer und Rate-Limits \\
Helsinki OPUS-MT & \wmark & 6 & Open-Source-Alternative, mehr Aufwand \\
OpenAI GPT-4 & \xmark & -- & Zu langsam, hohe Kosten, strikte API-Limits \\
Meta NLLB-200 & \xmark & -- & Nicht kommerziell nutzbar (CC-BY-NC) \\
\bottomrule
\end{tabular}
\end{table}

Für den Demonstrator werden DeepL und OPUS-MT implementiert.

\textbf{DeepL API} als Qualitätsführer: DeepL bietet die höchste Übersetzungsqualität für europäische Sprachen,
vollständige DSGVO-Konformität mit Serverstandort Deutschland und eine gut dokumentierte REST-API.

\textbf{Helsinki OPUS-MT} als Open-Source-Alternative: OPUS-MT ermöglicht einen direkten Vergleich mit einer
selbstgehosteten Lösung ohne externe API-Abhängigkeit \parencite{reddit2022nllb}. Die Modelle sind unter CC-BY 4.0
frei kommerziell nutzbar und können lokal über Hugging Face Transformers betrieben werden.

Diese Kombination ermöglicht im Demonstrator einen aussagekräftigen Vergleich zwischen
einer kommerziellen Cloud-Lösung und einer selbstgehosteten Open-Source-Alternative.

\section{Erläuterung zur Umsetzung}

\subsection{Architektur}
Das Backend besteht aus einer FastAPI-basierten REST-API mit zwei separaten Übersetzungs-Endpunkten 
(\texttt{/translate/deepl} und \texttt{/translate/opus}) sowie einem Health-Check-Endpunkt. Die DeepL-Integration 
nutzt die offizielle Python-Bibliothek \texttt{deepl} mit asynchroner Ausführung über \texttt{asyncio}. 
Die automatische Spracherkennung wird direkt von der DeepL-API bereitgestellt.

Für OPUS-MT werden die Helsinki-NLP-Modelle über Hugging Face Transformers geladen. Da nicht alle Sprachpaare 
direkt verfügbar sind, wurde ein Pivot-Mechanismus implementiert: Übersetzungen wie DE$\rightarrow$FR erfolgen über den 
Zwischenschritt DE$\rightarrow$EN$\rightarrow$FR. Ein LRU-Cache speichert bis zu 12 geladene OPUS-MT-Modelle, um wiederholte Ladezeiten zu vermeiden.

Das Frontend besteht aus einer HTML/JavaScript-Weboberfläche mit zwei nebeneinander angeordneten Übersetzungsfeldern, eines für jedes Modell (siehe Abbildung~\ref{fig:frontend}).
Die Sprachauswahl erfolgt über Buttons für die vier unterstützten Sprachen (DE, EN, FR, ES).

\subsection{EU AI Act Konformität}

Die API-Responses enthalten das Feld \texttt{ai\_generated: true} zur Kennzeichnung KI-generierter Inhalte gemäß EU AI Act Transparenzpflicht.
Das System wird als Niedrigrisiko-KI eingestuft, da es ausschließlich für Übersetzungsaufgaben ohne autonome Entscheidungsfindung eingesetzt wird.

\subsection{Abgrenzung}

Der Demonstrator erfüllt alle Must-Anforderungen der Anforderungsliste. Einige Should-Anforderungen wie API-Key-basierte Authentifizierung, 
HTTPS-Verschlüsselung, Batch-Übersetzung und Request-Logging wurden bewusst nicht implementiert, da diese für einen Demonstrator den Rahmen 
sprengen würden. Diese Funktionen wären für einen produktiven Einsatz erforderlich, sind aber für die Demonstration der Kernfunktionalität nicht notwendig.

\vspace{0.5cm}
\textbf{Repository:} \url{https://github.com/svenb23/KI-Translator}

\clearpage
\appendix
\section{Anhang}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{Frontend.png}
\caption{Weboberfläche des Demonstrators mit zwei nebeneinander angeordneten Übersetzungsfeldern für DeepL und OPUS-MT}
\label{fig:frontend}
\end{figure}

\clearpage
\printbibliography

\end{document}
